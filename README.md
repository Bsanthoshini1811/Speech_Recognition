# Speech_Recognition

## Introduction.
In today's digital age, education has surpassed the boundaries of traditional classrooms, thanks to the proliferation of e-learning platforms. However, in the middle of this transformation, a significant challenge persists ensuring that educational content is accessible to learners of diverse backgrounds and abilities. Imagine trying to learn from an online lecture, only to be hindered by accents or dialects that make understanding difficult. This is the reality faced by many learners worldwide. Our project, driven by a passion for inclusivity and accessibility in education, aims to tackle this challenge. By developing an innovative speech transcription model, we aspire to break down barriers and empower learners from all walks of life to engage effectively with educational content. To achieve our goal, we start by converting audio files into Mel-frequency cepstral coefficients (MFCCs), a technique widely used in audio signal processing. MFCCs allow us to extract essential features from the sound spectrum, enabling our model to understand spoken language more effectively. Additionally, we perform a train-test split to ensure that our model is trained on a diverse dataset while also being evaluated on unseen data.

We don't stop there. We rigorously evaluate our model's performance using metrics such as Loss function and accuracy between the predicted outputs and actual label, we can further decode the outputs using decode function but that part is left out due to constraint in computation resources, also these output sequences require preprocessing that can be changed to texts but now the outputs are in the form of sequences so we transformed our labels into the sequences further details will be explained below in the Notebook. These metrics allow us to assess how accurately our model transcribes speech and how well it generalizes to new data. We compare the performance of different models, including Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU), to identify the most effective approach.

Ultimately, our goal is to select the model that achieves the highest accuracy. By doing so, we can pave the way for a more inclusive and accessible future in ed-tech platforms, where every learner has the opportunity to thrive. So, let's get into it!
